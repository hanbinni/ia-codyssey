# crawling_KBS.py

from requests_html import HTMLSession
from bs4 import BeautifulSoup

BASE_URL = "http://news.kbs.co.kr"

def crawl_kbs_headlines():
    """KBS ë©”ì¸ í˜ì´ì§€ì—ì„œ í—¤ë“œë¼ì¸ ë‰´ìŠ¤(ë©”ì¸+ì„œë¸Œ)ë¥¼ í¬ë¡¤ë§"""

    session = HTMLSession()
    r = session.get(BASE_URL)

    # JS ì‹¤í–‰ (ë™ì  ë Œë”ë§ ì²˜ë¦¬)
    r.html.render(timeout=30, sleep=5)

    soup = BeautifulSoup(r.html.html, "html.parser")

    # ë©”ì¸ í—¤ë“œë¼ì¸ (main-news-wrapper)
    main_news = []
    for box in soup.select(".main-news-wrapper a.main-news"):
        title = box.select_one("p.title").get_text(strip=True) if box.select_one("p.title") else ""
        desc = box.select_one("p.news-txt").get_text(strip=True) if box.select_one("p.news-txt") else ""
        link = BASE_URL + box.get("href", "")
        main_news.append({"title": title, "desc": desc, "link": link})

    # ì„œë¸Œ í—¤ë“œë¼ì¸ (small-sub-news-wrapper)
    sub_news = []
    for box in soup.select(".small-sub-news-wrapper a"):
        title = box.select_one("p.title").get_text(strip=True) if box.select_one("p.title") else ""
        link = BASE_URL + box.get("href", "")
        sub_news.append({"title": title, "desc": "", "link": link})

    return main_news + sub_news


if __name__ == "__main__":
    headlines = crawl_kbs_headlines()

    print("ğŸ“Œ KBS ì£¼ìš” í—¤ë“œë¼ì¸ ë‰´ìŠ¤\n")
    for i, news in enumerate(headlines, 1):
        print(f"{i}. {news['title']}")
        if news['desc']:
            print(f"   â”” ìš”ì•½: {news['desc']}")
        print(f"   â”” ë§í¬: {news['link']}\n")
